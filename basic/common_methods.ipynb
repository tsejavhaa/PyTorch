{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93472cfd",
   "metadata": {},
   "source": [
    "# Common PyTorch Functions and Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea08c8f",
   "metadata": {},
   "source": [
    "## Tensor Creation\n",
    "\n",
    "### torch.tensor(): Creates a tensor from data (like a list or array)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00738390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "data = [[1, 2], [3, 4]]\n",
    "x = torch.tensor(data)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d9af14",
   "metadata": {},
   "source": [
    "### torch.zeros(): Creates a tensor filled with 0s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5f4884f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.zeros(2, 3) # 2 rows, 3 columns of 0.0\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06da8d47",
   "metadata": {},
   "source": [
    "### torch.ones(): Creates a tensor filled with 1s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ededff8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(2,3,4) # 1D tensor with five 1.0s\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4b0f17",
   "metadata": {},
   "source": [
    "### torch.rand(): Random values from a uniform distribution $[0, 1)$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3265c725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6515, 0.4992, 0.3089, 0.5694],\n",
       "        [0.9685, 0.2066, 0.6741, 0.1608],\n",
       "        [0.8231, 0.6310, 0.9926, 0.0780]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(3, 4) # Useful for initializing weights randomly\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2617112",
   "metadata": {},
   "source": [
    "### torch.randn(): Random values from a normal distribution (mean 0, var 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc7863bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.9755, -2.8533, -0.0843],\n",
       "        [ 1.2666, -0.2682, -0.5117],\n",
       "        [-0.4182,  1.0114, -1.2105]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3, 3) # Often preferred for initializing neural network layers\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6528b3fc",
   "metadata": {},
   "source": [
    "### torch.arange(): Returns a 1D tensor with a range of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b673081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 4, 6, 8])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(start=0, end=10, step=2) # tensor([0, 2, 4, 6, 8])\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011d65b7",
   "metadata": {},
   "source": [
    "### torch.linspace(): Creates evenly spaced values between a start and end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57312829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.2500, 0.5000, 0.7500, 1.0000])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.linspace(start=0, end=1, steps=5) # tensor([0.0, 0.25, 0.5, 0.75, 1.0])\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918e9417",
   "metadata": {},
   "source": [
    "### torch.eye(): Creates an identity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd77d762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.eye(3) # 3x3 Identity matrix\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11cbe5d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.eye(4, 2) # 4x2 Identity matrix\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "195e9a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.eye(5, 3) # 5x3 Identity matrix\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5ba9ca",
   "metadata": {},
   "source": [
    "### torch.full(): Creates a tensor filled with a specific value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6da172c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.1416, 3.1416],\n",
       "        [3.1416, 3.1416]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.full((2, 2), 3.14159) # A 2x2 tensor of Pi\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e086fe51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.1416, 3.1416, 3.1416],\n",
       "        [3.1416, 3.1416, 3.1416],\n",
       "        [3.1416, 3.1416, 3.1416],\n",
       "        [3.1416, 3.1416, 3.1416]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.full((4, 3), 3.14159) # A 4x3 tensor of Pi\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fdc17d",
   "metadata": {},
   "source": [
    "### torch.from_numpy(): Converts a NumPy array into a PyTorch tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac0d81ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "n = np.array([1, 2, 3])\n",
    "t = torch.from_numpy(n)\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e877d62",
   "metadata": {},
   "source": [
    "### torch.zeros_like(): Creates a tensor of 0s with the same shape as another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f60e2aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.zeros_like(x) # x is any existing tensor\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf4ebd8",
   "metadata": {},
   "source": [
    "### torch.ones_like(): Creates a tensor of 1s with the same shape as another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38bcdca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.ones_like(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e023c46a",
   "metadata": {},
   "source": [
    "### dtype: Concept of data types (e.g., torch.float32, torch.int64)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "feb2b905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]], dtype=torch.float16)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(2, 2, dtype=torch.float16) # Saves memory compared to float32\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2c1098",
   "metadata": {},
   "source": [
    "### device: Concept of where the tensor lives (cpu, cuda, or mps)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "983a8d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9810, 0.5945, 0.9302],\n",
       "        [0.4438, 0.0609, 0.8142],\n",
       "        [0.7583, 0.6873, 0.9753]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Moving a tensor to GPU if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "x = torch.rand(3, 3).to(device)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2ffbec",
   "metadata": {},
   "source": [
    "### requires_grad: A flag that enables gradient tracking for a tensor.\n",
    "\n",
    "- If set to True, PyTorch starts tracking every operation on this tensor for automatic differentiation (calculating gradients)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "088f96f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6116,  0.8640,  0.6185, -0.6311,  0.3483],\n",
       "        [ 1.5945,  0.4967,  0.2957, -1.7618,  0.9806],\n",
       "        [ 0.3773,  0.7827, -0.9259,  0.1817,  0.5624],\n",
       "        [-0.9019,  0.5726,  0.3483, -1.5594, -0.7715],\n",
       "        [ 1.6089,  1.4334, -0.0570,  0.2737, -0.0631],\n",
       "        [-0.1730, -1.1494,  0.1716,  0.6753,  0.7992],\n",
       "        [ 0.8921, -0.8448,  0.9771,  0.8726,  1.2721],\n",
       "        [ 0.1113, -1.3985, -0.1056, -1.3583, -1.9216],\n",
       "        [-0.7093, -0.1859,  1.5060, -0.5990,  1.0691],\n",
       "        [-0.5215, -1.1779,  0.5231,  0.0641, -0.7135]], requires_grad=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weights in a model need this to be True to learn!\n",
    "weights = torch.randn(10, 5, requires_grad=True) # Default is False\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b7ec13",
   "metadata": {},
   "source": [
    "## Tensor Shaping & Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c61d6fa",
   "metadata": {},
   "source": [
    "### view(): \n",
    "- Returns a new tensor with the same data but a different shape. The new shape must have the same number of elements as the original.\n",
    "\n",
    "- Constraint: It only works on \"contiguous\" tensors (data stored in a single block of memory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bd086135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: torch.Size([4, 4])\n",
      "Reshaped to 2x8: torch.Size([2, 8])\n",
      "Reshaped to 8x2: torch.Size([8, 2])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, 4) # 16 elements\n",
    "print(\"Original shape:\", x.shape)\n",
    "y = x.view(2, 8)      # Reshaped to 2x8\n",
    "print(\"Reshaped to 2x8:\", y.shape)\n",
    "z = x.view(-1, 2)     # -1 tells PyTorch to \"figure out\" the dimension (results in 8x2)\n",
    "print(\"Reshaped to 8x2:\", z.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a97a8e",
   "metadata": {},
   "source": [
    "### **reshape():** \n",
    "- Similar to view, but more robust. If the tensor isn't contiguous, it will copy the data to a new memory block automatically.\n",
    "\n",
    "### **flatten():** \n",
    "- Collapses a range of dimensions into one. Often used to turn a 2D image into a 1D vector before a fully connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "79106c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: torch.Size([3, 4])\n",
      "Reshaped to 2x6: torch.Size([2, 6])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, 4)\n",
    "print(\"Original shape:\", x.shape)\n",
    "y = x.reshape(2, 6)  # Reshaped to 2x6\n",
    "print(\"Reshaped to 2x6:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0785d992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: torch.Size([1, 28, 28])\n",
      "Flattened shape: torch.Size([784])\n",
      "Reshaped to 1D shape: torch.Size([784])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, 28, 28)\n",
    "print(\"Original shape:\", x.shape)\n",
    "y = x.flatten() # Shape: [784]\n",
    "print(\"Flattened shape:\", y.shape)\n",
    "z = x.view(-1)  # Shape: [784]\n",
    "print(\"Reshaped to 1D shape:\", z.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d5d8d5",
   "metadata": {},
   "source": [
    "### **transpose():**\n",
    "- Swaps exactly two dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8554584d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3671,  1.2576, -0.6083],\n",
       "        [ 1.2173, -0.3585,  0.1795],\n",
       "        [ 1.2256,  0.4310,  0.6151],\n",
       "        [-0.9671,  1.2287, -1.2524],\n",
       "        [ 0.1616, -1.1140,  0.2838]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3, 5)\n",
    "y = x.transpose(0, 1) # Shape: [5, 3]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f4074dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape:\n",
      " tensor([[ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  5,  9],\n",
       "        [ 2,  6, 10],\n",
       "        [ 3,  7, 11],\n",
       "        [ 4,  8, 12]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1,2,3,4], [5,6,7,8], [9,10,11,12]])  # 3x4 tensor\n",
    "print(\"Original shape:\\n\", x)\n",
    "y = x.t()  # Transposed to 4x3\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4d0997",
   "metadata": {},
   "source": [
    "### **permute():** \n",
    "- A more powerful version of transpose that can reorder any number of dimensions at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5450c611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: torch.Size([16, 3, 64, 64])\n",
      "Permuted shape: torch.Size([16, 64, 64, 3])\n"
     ]
    }
   ],
   "source": [
    "# Useful for converting (Batch, Channels, H, W) -> (Batch, H, W, Channels)\n",
    "x = torch.randn(16, 3, 64, 64)\n",
    "print(\"Original shape:\", x.shape)\n",
    "y = x.permute(0, 2, 3, 1) # Shape: [16, 64, 64, 3]\n",
    "print(\"Permuted shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afbdac3",
   "metadata": {},
   "source": [
    "### **squeeze():** \n",
    "- Removes all dimensions of size 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6798fddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: torch.Size([1, 5, 1, 3])\n",
      "Squeezed shape: torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(1, 5, 1, 3)\n",
    "print(\"Original shape:\", x.shape)\n",
    "y = x.squeeze() # Shape: [5, 3]\n",
    "print(\"Squeezed shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d12f1ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: torch.Size([1, 2, 3, 4])\n",
      "Squeezed shape: torch.Size([2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(1, 2, 3, 4)\n",
    "print(\"Original shape:\", x.shape)\n",
    "y = x.squeeze() # Shape: [2, 3, 4], Removes only dimension 1 (second dimension) \n",
    "print(\"Squeezed shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff62ef4",
   "metadata": {},
   "source": [
    "### **unsqueeze():** \n",
    "- Adds a dimension of size 1 at the specified index. This is essential for adding a \"batch\" dimension to a single input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2189ed1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: torch.Size([3, 224, 224])\n",
      "Unsqueezed shape: torch.Size([1, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, 224, 224) # A single RGB image\n",
    "print(\"Original shape:\", x.shape)\n",
    "y = x.unsqueeze(0)           # Shape: [1, 3, 224, 224] (Ready for a model)\n",
    "print(\"Unsqueezed shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4806fe",
   "metadata": {},
   "source": [
    "### **torch.cat():** \n",
    "- Concatenates tensors along an existing dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "317117c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated shape: torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2, 3)\n",
    "b = torch.randn(2, 3)\n",
    "c = torch.cat((a, b), dim=0) # Shape: [4, 3]\n",
    "print(\"Concatenated shape:\", c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d6ed18",
   "metadata": {},
   "source": [
    "### **torch.stack():** \n",
    "- Joins tensors along a new dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a4187d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked shape: torch.Size([2, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "c = torch.stack((a, b), dim=0) # Shape: [2, 2, 3]\n",
    "print(\"Stacked shape:\", c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9f7e8d",
   "metadata": {},
   "source": [
    "### **torch.split():** \n",
    "- Breaks a tensor into chunks of a specific size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9a8dea44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split tensors (size=2 along dim=1): (tensor([[-1.2095,  0.0408],\n",
      "        [-0.6972,  1.3195],\n",
      "        [ 0.7223, -0.2128],\n",
      "        [ 1.5339,  0.1758]]), tensor([[-1.0989, -0.3553],\n",
      "        [-0.7979,  0.3025],\n",
      "        [-0.0906,  0.8457],\n",
      "        [-0.3977,  0.3002]]))\n",
      "Split tensors (sizes [1,3]): (tensor([[-1.2095],\n",
      "        [-0.6972],\n",
      "        [ 0.7223],\n",
      "        [ 1.5339]]), tensor([[ 0.0408, -1.0989, -0.3553],\n",
      "        [ 1.3195, -0.7979,  0.3025],\n",
      "        [-0.2128, -0.0906,  0.8457],\n",
      "        [ 0.1758, -0.3977,  0.3002]]))\n"
     ]
    }
   ],
   "source": [
    "# Example: split tensor into chunks of size 2 along dim=1\n",
    "x = torch.randn(4, 4)\n",
    "c = torch.split(x, 2, dim=1)  # returns a tuple of tensors\n",
    "print(\"Split tensors (size=2 along dim=1):\", c)\n",
    "\n",
    "# Example: split with a list of sizes\n",
    "d = torch.split(x, [1, 3], dim=1)\n",
    "print(\"Split tensors (sizes [1,3]):\", d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f0861c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: torch.Size([4, 6])\n",
      "Number of chunks: 2\n",
      "Shape of each chunk: [torch.Size([2, 6]), torch.Size([2, 6])]\n"
     ]
    }
   ],
   "source": [
    "# torch.chunk(): Splits a tensor into a specific number of chunks along a dimension\n",
    "x = torch.randn(4, 6)\n",
    "print(\"Original shape:\", x.shape)\n",
    "chunks = torch.chunk(x, chunks=2, dim=0)  # Split into 2 chunks along dimension 0\n",
    "print(\"Number of chunks:\", len(chunks))\n",
    "print(\"Shape of each chunk:\", [chunk.shape for chunk in chunks])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ecaebf",
   "metadata": {},
   "source": [
    "### **gather():** \n",
    "- Collects values from a tensor along an axis using an index tensor. (Common in Reinforcement Learning to select specific action probabilities)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5ad6e85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:\n",
      " tensor([[-1.8226, -1.2664, -1.1982],\n",
      "        [-0.6893,  1.5571, -0.2017]])\n",
      "idx1:\n",
      " tensor([[0, 2, 1],\n",
      "        [1, 0, 2]])\n",
      "gather(a, dim=1, idx1):\n",
      " tensor([[-1.8226, -1.1982, -1.2664],\n",
      "        [ 1.5571, -0.6893, -0.2017]])\n",
      "\n",
      "b:\n",
      " tensor([[-1.4220,  0.7331, -1.4626],\n",
      "        [ 0.2823, -1.3231, -1.4902]])\n",
      "idx2:\n",
      " tensor([[1, 0, 1],\n",
      "        [0, 1, 0]])\n",
      "gather(b, dim=0, idx2):\n",
      " tensor([[ 0.2823,  0.7331, -1.4902],\n",
      "        [-1.4220, -1.3231, -1.4626]])\n",
      "\n",
      "x:\n",
      " tensor([[ 0.5097, -0.5562,  0.1617, -0.4310, -0.4496, -0.2203],\n",
      "        [-0.0255,  0.5188, -0.6625, -0.6019,  0.1647,  0.8892],\n",
      "        [ 1.1193, -0.9448,  0.5424, -0.4241, -0.0626, -1.5036],\n",
      "        [ 0.2396, -0.5232, -0.5933, -0.1551, -3.1055, -0.5005]])\n",
      "idx3 (one index per row):\n",
      " tensor([[3],\n",
      "        [2],\n",
      "        [0],\n",
      "        [4]])\n",
      "gather(x, dim=1, idx3):\n",
      " tensor([[-0.4310],\n",
      "        [-0.6625],\n",
      "        [ 1.1193],\n",
      "        [-3.1055]])\n",
      "\n",
      "Selected action values from weights:\n",
      " tensor([[ 0.6116],\n",
      "        [ 0.4967],\n",
      "        [-0.9259],\n",
      "        [-1.5594],\n",
      "        [-0.0631],\n",
      "        [-0.1730],\n",
      "        [-0.8448],\n",
      "        [-0.1056],\n",
      "        [-0.5990],\n",
      "        [-0.7135]], grad_fn=<GatherBackward0>)\n",
      "\n",
      "y.shape: torch.Size([1, 2, 3, 4])\n",
      "idx_y.shape: torch.Size([1, 2, 3, 1])\n",
      "gather(y, dim=3, idx_y).shape: torch.Size([1, 2, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "# Examples of torch.gather using tensors already defined in the notebook.\n",
    "\n",
    "# 1) 2D gather along dim=1 (select columns per row) using 'a' (2x3)\n",
    "idx1 = torch.tensor([[0, 2, 1],\n",
    "                     [1, 0, 2]], dtype=torch.long)\n",
    "res1 = torch.gather(a, dim=1, index=idx1)\n",
    "print(\"a:\\n\", a)\n",
    "print(\"idx1:\\n\", idx1)\n",
    "print(\"gather(a, dim=1, idx1):\\n\", res1)\n",
    "\n",
    "# 2) gather along dim=0 (select rows per column) using 'b' (2x3)\n",
    "idx2 = torch.tensor([[1, 0, 1],\n",
    "                     [0, 1, 0]], dtype=torch.long)\n",
    "res2 = torch.gather(b, dim=0, index=idx2)\n",
    "print(\"\\nb:\\n\", b)\n",
    "print(\"idx2:\\n\", idx2)\n",
    "print(\"gather(b, dim=0, idx2):\\n\", res2)\n",
    "\n",
    "# 3) Select one column per row from x (4x6)\n",
    "idx3 = torch.randint(0, x.size(1), (x.size(0), 1), dtype=torch.long)  # shape [4,1]\n",
    "res3 = torch.gather(x, dim=1, index=idx3)  # shape [4,1]\n",
    "print(\"\\nx:\\n\", x)\n",
    "print(\"idx3 (one index per row):\\n\", idx3)\n",
    "print(\"gather(x, dim=1, idx3):\\n\", res3)\n",
    "\n",
    "# 4) RL-style: select action-values from 'weights' (10x5) given action indices\n",
    "actions = torch.tensor([0, 1, 2, 3, 4, 0, 1, 2, 3, 4], dtype=torch.long).unsqueeze(1)  # [10,1]\n",
    "selected_values = torch.gather(weights, dim=1, index=actions)  # [10,1]\n",
    "print(\"\\nSelected action values from weights:\\n\", selected_values)\n",
    "\n",
    "# 5) 4D gather: use 'y' (1x2x3x4) and pick one element from last dim per position\n",
    "idx_y = torch.randint(0, y.size(-1), (y.size(0), y.size(1), y.size(2), 1), dtype=torch.long)  # [...,1]\n",
    "res_y = torch.gather(y, dim=3, index=idx_y)\n",
    "print(\"\\ny.shape:\", y.shape)\n",
    "print(\"idx_y.shape:\", idx_y.shape)\n",
    "print(\"gather(y, dim=3, idx_y).shape:\", res_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61d3f4f",
   "metadata": {},
   "source": [
    "### **scatter_():** \n",
    "- The opposite of gather; it writes values into a tensor at specified indices. (The _ means it happens in-place)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "776f99cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scatter_ basic ->\n",
      " tensor([[10., 30., 20.],\n",
      "        [50., 40., 60.]])\n",
      "scatter_add_ ->\n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "one_hot shape: torch.Size([10, 5])\n",
      "tensor([[1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1.]])\n",
      "target_y.sum() (number of scattered ones): 6.0\n"
     ]
    }
   ],
   "source": [
    "# 1) Basic scatter_: place src values into target according to idx1 (shape [2,3])\n",
    "target = torch.zeros_like(a)\n",
    "src = torch.tensor([[10., 20., 30.],\n",
    "                    [40., 50., 60.]], dtype=target.dtype)\n",
    "target.scatter_(dim=1, index=idx1, src=src)\n",
    "print(\"scatter_ basic ->\\n\", target)\n",
    "\n",
    "# 2) scatter_add_: accumulate values at indices (useful when indices repeat)\n",
    "t2 = torch.zeros(2, 3, dtype=a.dtype)\n",
    "src2 = torch.tensor([[1., 1., 1.],\n",
    "                     [1., 1., 1.]], dtype=t2.dtype)\n",
    "t2.scatter_add_(dim=1, index=idx1, src=src2)\n",
    "print(\"scatter_add_ ->\\n\", t2)\n",
    "\n",
    "# 3) One-hot encoding from actions (common RL pattern)\n",
    "one_hot = torch.zeros(actions.size(0), weights.size(1), dtype=weights.dtype, device=weights.device)\n",
    "one_hot.scatter_(1, actions, 1.0)\n",
    "print(\"one_hot shape:\", one_hot.shape)\n",
    "print(one_hot[:5])\n",
    "\n",
    "# 4) Scatter into 4D tensor using idx_y (inverse-style of the gather example)\n",
    "target_y = torch.zeros_like(y)\n",
    "src_y = torch.ones_like(idx_y, dtype=y.dtype)\n",
    "target_y.scatter_(3, idx_y, src_y)  # write 1.0 at positions specified in idx_y along last dim\n",
    "print(\"target_y.sum() (number of scattered ones):\", target_y.sum().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7c8516",
   "metadata": {},
   "source": [
    "### **expand():** \n",
    "- Efficiently makes a tensor look larger by \"repeating\" it without actually copying the data in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "de07a6a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1],\n",
       "        [2, 2, 2, 2]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1], [2]]) # Shape: [2, 1]\n",
    "y = x.expand(2, 4)           # Shape: [2, 4], but uses no extra memory!\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f68aad",
   "metadata": {},
   "source": [
    "### **repeat():** \n",
    "- Unlike expand, this physically copies the data to fill the new shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1d412002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5097, -0.5562,  0.1617, -0.4310, -0.4496, -0.2203,  0.5097, -0.5562,\n",
       "          0.1617, -0.4310, -0.4496, -0.2203,  0.5097, -0.5562,  0.1617, -0.4310,\n",
       "         -0.4496, -0.2203,  0.5097, -0.5562,  0.1617, -0.4310, -0.4496, -0.2203],\n",
       "        [-0.0255,  0.5188, -0.6625, -0.6019,  0.1647,  0.8892, -0.0255,  0.5188,\n",
       "         -0.6625, -0.6019,  0.1647,  0.8892, -0.0255,  0.5188, -0.6625, -0.6019,\n",
       "          0.1647,  0.8892, -0.0255,  0.5188, -0.6625, -0.6019,  0.1647,  0.8892],\n",
       "        [ 1.1193, -0.9448,  0.5424, -0.4241, -0.0626, -1.5036,  1.1193, -0.9448,\n",
       "          0.5424, -0.4241, -0.0626, -1.5036,  1.1193, -0.9448,  0.5424, -0.4241,\n",
       "         -0.0626, -1.5036,  1.1193, -0.9448,  0.5424, -0.4241, -0.0626, -1.5036],\n",
       "        [ 0.2396, -0.5232, -0.5933, -0.1551, -3.1055, -0.5005,  0.2396, -0.5232,\n",
       "         -0.5933, -0.1551, -3.1055, -0.5005,  0.2396, -0.5232, -0.5933, -0.1551,\n",
       "         -3.1055, -0.5005,  0.2396, -0.5232, -0.5933, -0.1551, -3.1055, -0.5005]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x.repeat(1, 4) # Shape: [2, 4], but creates a new, larger memory block.\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37562d0b",
   "metadata": {},
   "source": [
    "## Mathematical Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa75750a",
   "metadata": {},
   "source": [
    "### add() / +: Adds two tensors or a tensor and a scalar.\n",
    "\n",
    "### sub() / -: Subtracts one tensor from another.\n",
    "\n",
    "### mul() / *: Performs element-wise multiplication (Hadamard product).\n",
    "\n",
    "### div() / /: Performs element-wise division."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "46559ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[14, 16, 18, 20],\n",
      "        [22, 24, 26, 28],\n",
      "        [30, 32, 34, 36]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1,2,3,4], [5,6,7,8], [9,10,11,12]])  # 3x4 tensor\n",
    "b = torch.tensor([[13,14,15,16], [17,18,19,20], [21,22,23,24]])  # 3x4 tensor\n",
    "c = a + b # Element-wise addition\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c03cdf49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[14, 16, 18, 20],\n",
      "        [22, 24, 26, 28],\n",
      "        [30, 32, 34, 36]])\n"
     ]
    }
   ],
   "source": [
    "c = torch.add(a, b) # Element-wise addition\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fe80cb24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-12, -12, -12, -12],\n",
      "        [-12, -12, -12, -12],\n",
      "        [-12, -12, -12, -12]])\n"
     ]
    }
   ],
   "source": [
    "c = a - b # Element-wise subtraction\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3e2b9cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[12, 12, 12, 12],\n",
      "        [12, 12, 12, 12],\n",
      "        [12, 12, 12, 12]])\n"
     ]
    }
   ],
   "source": [
    "c = torch.sub(b, a) # Element-wise subtraction\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ab339692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 8])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1, 2])\n",
    "b = torch.tensor([3, 4])\n",
    "print(a * b) # tensor([3, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7a396467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0769, 0.1429, 0.2000, 0.2500],\n",
      "        [0.2941, 0.3333, 0.3684, 0.4000],\n",
      "        [0.4286, 0.4545, 0.4783, 0.5000]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.div(a, b)) # tensor([0.3333, 0.5000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47868a84",
   "metadata": {},
   "source": [
    "### matmul(): \n",
    "- The generic matrix multiplication function. It handles 1D, 2D, and high-dimensional tensors with broadcasting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "03c07fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix multiplication result shape: torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "# Matrix (2x3) @ Matrix (3x2) -> (2x2)\n",
    "mat1 = torch.randn(2, 3)\n",
    "mat2 = torch.randn(3, 2)\n",
    "res = torch.matmul(mat1, mat2) # Or mat1 @ mat2\n",
    "print(\"Matrix multiplication result shape:\", res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fab493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 58,  64],\n",
       "        [139, 154]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat1 = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "mat2 = torch.tensor([[7, 8], [9, 10], [11, 12]])\n",
    "res = torch.matmul(mat1, mat2) # Shape: [2, 2]\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5ecc4969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 30,  24,  18],\n",
       "        [ 84,  69,  54],\n",
       "        [138, 114,  90],\n",
       "        [192, 159, 126]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat1 = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]]) # Shape: [4, 3]\n",
    "mat2 = torch.tensor([[9, 8, 7], [6, 5, 4], [3, 2, 1]]) # Shape: [3, 3]\n",
    "mat3 = torch.matmul(mat1, mat2) # Shape: [4, 3]\n",
    "mat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3e318725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.8558,  1.7894, -2.6648, -3.5824,  5.1454],\n",
       "        [-2.0461, -1.6274,  0.8376,  1.0412, -1.2940],\n",
       "        [-3.8472, -0.6393,  0.0744,  3.2738, -0.8600],\n",
       "        [ 1.1481,  0.1155, -0.9582, -1.5022,  2.0582]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat1 = torch.randn(4, 3)\n",
    "mat2 = torch.randn(3, 5)\n",
    "mat3 = torch.matmul(mat1, mat2) # Shape: [4, 5]\n",
    "mat3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a296ebf",
   "metadata": {},
   "source": [
    "### mm(): \n",
    "- A stricter version of matrix multiplication that only works for two 2D tensors (matrices). Use this for speed when you know your data is 2D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "46752958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.9101, -0.2616],\n",
       "        [ 0.7204,  0.8979]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat1 = torch.randn(2, 3) # 2D tensor\n",
    "mat2 = torch.randn(3, 2) # 2D tensor\n",
    "res = torch.mm(mat1, mat2) # 2D Matrix multiplication\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b8e865",
   "metadata": {},
   "source": [
    "### bmm(): \n",
    "- Batch Matrix Multiplication. Used when you have a batch of matrices (e.g., shape $[B, N, M]$) and want to multiply them without a loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "79367c32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.4323, -1.5249, -0.9572, -1.9377,  0.2226],\n",
       "         [-1.5481, -0.7953, -0.8928, -1.3014,  0.0399],\n",
       "         [-0.4902,  0.5933,  0.1729,  0.4578, -0.4212],\n",
       "         [-0.4300, -0.9472, -0.3385, -0.9112,  0.3932]],\n",
       "\n",
       "        [[-2.7766,  2.9747, -1.2182,  4.4545, -2.1316],\n",
       "         [-0.5441,  1.1734,  0.2189,  1.1327, -0.2883],\n",
       "         [-0.3703,  0.5993,  0.7820,  0.2181, -0.4616],\n",
       "         [ 0.2117, -0.0614, -0.4298,  0.1176,  0.3820]]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat1 = torch.randn(2, 4, 3)\n",
    "mat2 = torch.randn(2, 3, 5)\n",
    "res = torch.bmm(mat1, mat2) # Shape: [2, 4, 5]\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f5ff9f",
   "metadata": {},
   "source": [
    "### sum(), mean(), std(), var(): \n",
    "- Computes the sum, average, standard deviation, and variance. You can compute these across the whole tensor or along a specific dim.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c4ecb5fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0703,  0.6337, -0.9541, -0.9055,  1.9880],\n",
       "        [-0.9852, -1.6449, -0.5266, -0.1445, -1.8555],\n",
       "        [ 1.4578, -0.6934,  0.8816, -0.2342,  1.0401],\n",
       "        [ 0.0774,  1.9772, -0.8595,  0.5405,  0.8523]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(4, 5)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f2c2513f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a.sum(): tensor(0.7154)\n",
      "torch.sum(a, dtype=torch.float32): tensor(0.7154)\n",
      "a.sum(dim=1): tensor([ 0.8324, -5.1568,  2.4518,  2.5879])\n",
      "res.sum(dim=(0,1)): tensor([-8.3798,  2.0119, -2.6627,  2.2303, -2.2650])\n",
      "mat3.mean(): tensor(0.0159)\n",
      "mat3.mean(dim=1, keepdim=True): tensor([[ 0.9087],\n",
      "        [-0.6177],\n",
      "        [-0.3997],\n",
      "        [ 0.1723]])\n",
      "z.std(): tensor(1.0034)\n",
      "z.std(unbiased=False): tensor(1.0027)\n",
      "z.var(): tensor(1.0067)\n",
      "z.var(unbiased=False): tensor(1.0054)\n",
      "weights.mean(dim=1): tensor([ 0.3623,  0.3211,  0.1957, -0.4624,  0.6392,  0.0647,  0.6338, -0.9345,\n",
      "         0.2162, -0.3652], grad_fn=<MeanBackward1>)\n",
      "torch.from_numpy(n).sum(): tensor(6)\n"
     ]
    }
   ],
   "source": [
    "# SUM\n",
    "print(\"a.sum():\", a.sum())                          # sum all elements of 2D tensor 'a'\n",
    "print(\"torch.sum(a, dtype=torch.float32):\", torch.sum(a, dtype=torch.float32))  # specify dtype\n",
    "print(\"a.sum(dim=1):\", a.sum(dim=1))                # sum along columns -> per-row sums\n",
    "print(\"res.sum(dim=(0,1)):\", res.sum(dim=(0, 1)))   # sum over first two dims of 3D tensor -> shape [5]\n",
    "\n",
    "# MEAN\n",
    "print(\"mat3.mean():\", mat3.mean())                  # global mean\n",
    "print(\"mat3.mean(dim=1, keepdim=True):\", mat3.mean(dim=1, keepdim=True))  # mean per-row, keepdim\n",
    "\n",
    "# STD / VAR\n",
    "print(\"z.std():\", z.std())                          # standard deviation (unbiased=True by default)\n",
    "print(\"z.std(unbiased=False):\", z.std(unbiased=False))  # population std\n",
    "print(\"z.var():\", z.var())                          # variance (unbiased=True default)\n",
    "print(\"z.var(unbiased=False):\", z.var(unbiased=False))  # population variance\n",
    "\n",
    "# Useful aggregated examples\n",
    "print(\"weights.mean(dim=1):\", weights.mean(dim=1))  # per-row mean for a 2D tensor with requires_grad\n",
    "print(\"torch.from_numpy(n).sum():\", torch.from_numpy(n).sum())  # convert numpy array 'n' and sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ac9e72",
   "metadata": {},
   "source": [
    "### max() / min(): \n",
    "- Returns the maximum or minimum values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5af8c821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum and Minimum tensor(1.9880) tensor(-1.8555)\n"
     ]
    }
   ],
   "source": [
    "print(\"Maximum and Minimum\", a.max(), a.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4648a375",
   "metadata": {},
   "source": [
    "### argmax() / argmin(): \n",
    "- Returns the indices of the maximum or minimum values. This is how you determine the \"predicted class\" in classification.\n",
    "\n",
    "- Note on keepdim: When reducing, the dimension usually disappears. Setting keepdim=True maintains the original number of dimensions, which is helpful for broadcasting later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fb39934c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = torch.tensor([0.1, 0.7, 0.2])\n",
    "prediction = torch.argmax(probs) # tensor(1)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d079a9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:\n",
      " tensor([[ 0.0703,  0.6337, -0.9541, -0.9055,  1.9880],\n",
      "        [-0.9852, -1.6449, -0.5266, -0.1445, -1.8555],\n",
      "        [ 1.4578, -0.6934,  0.8816, -0.2342,  1.0401],\n",
      "        [ 0.0774,  1.9772, -0.8595,  0.5405,  0.8523]])\n",
      "argmax along dim=1: tensor([4, 3, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "# argmax() example with a 2D tensor\n",
    "print(\"a:\\n\", a)\n",
    "predictions = torch.argmax(a, dim=1)  # Get index of max value per row\n",
    "print(\"argmax along dim=1:\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73136836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = torch.tensor([0.1, 0.7, 0.2])\n",
    "prediction = torch.argmin(probs) # tensor(0)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0accc704",
   "metadata": {},
   "source": [
    "### abs(): Computes the absolute value element-wise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1ceab497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolutes value element-wise: tensor([[ 1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[-1, -2, -3, -4, -5], [6, 7, 8, 9, 10]])\n",
    "print(\"Absolutes value element-wise:\", torch.abs(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2c6b0100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original x:\n",
      " tensor([[ 1.2701, -1.1278,  0.4384],\n",
      "        [ 0.3268,  1.7379,  0.7190]])\n",
      "Absolutes value element-wise: tensor([[1.2701, 1.1278, 0.4384],\n",
      "        [0.3268, 1.7379, 0.7190]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2,3)\n",
    "print(\"Original x:\\n\", x)\n",
    "print(\"Absolutes value element-wise:\", torch.abs(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f68338",
   "metadata": {},
   "source": [
    "### exp(): Computes the exponential $e^x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "47d2b811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original x:\n",
      " tensor([[-1.0309,  0.6312,  1.8066],\n",
      "        [ 0.6729, -0.4591,  1.7287]])\n",
      "Exponential value:  tensor([[0.3567, 1.8799, 6.0897],\n",
      "        [1.9599, 0.6319, 5.6331]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 3) # Uninitialized tensor\n",
    "print(\"Original x:\\n\", x)\n",
    "print(\"Exponential value: \", torch.exp(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93d5d2f",
   "metadata": {},
   "source": [
    "### log(): Computes the natural logarithm $\\ln(x)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a1be579c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5247, -0.7139, -0.5295],\n",
      "        [-1.5583,  0.4529,  0.7406]])\n",
      "Natural logarithm:  tensor([[-0.6450,     nan,     nan],\n",
      "        [    nan, -0.7920, -0.3003]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2,3)\n",
    "print(x)\n",
    "print(\"Natural logarithm: \", torch.log(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ae359c",
   "metadata": {},
   "source": [
    "### pow(): Computes the power $x^y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4ff409dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 4, 9])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3])\n",
    "print(torch.pow(x, 2)) # tensor([1, 4, 9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c46a12e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1,  8, 27])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3])\n",
    "print(torch.pow(x, 3)) # tensor([1, 8, 27])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacccd44",
   "metadata": {},
   "source": [
    "### norm(): \n",
    "- Computes the vector or matrix norm.\n",
    "    - L2 Norm (Euclidean): $\\sqrt{\\sum |x_i|^2}$ — the default.\n",
    "    - L1 Norm (Manhattan): $\\sum |x_i|$ — often used for regularization to encourage sparsity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "998b7e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.)\n"
     ]
    }
   ],
   "source": [
    "v = torch.tensor([3.0, 4.0])\n",
    "print(torch.norm(v, p=2)) # tensor(5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "26015d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.)\n"
     ]
    }
   ],
   "source": [
    "v = torch.tensor([1.0, -1.0, 2.0, -2.0])\n",
    "print(torch.norm(v, p=1)) # tensor(6.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "14ee2fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3894, -1.4843,  1.1277, -0.3767],\n",
      "        [ 0.6728,  0.2587, -1.5491, -1.2233],\n",
      "        [ 0.6190,  0.8564, -0.1544, -1.9031]])\n",
      "tensor(3.5981)\n"
     ]
    }
   ],
   "source": [
    "v = torch.randn(3, 4)\n",
    "print(v)\n",
    "print(torch.norm(v, p='fro')) # Frobenius norm for 2D tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bc9648",
   "metadata": {},
   "source": [
    "## Autograd\n",
    "- It is the engine that automatically calculates derivatives (gradients) for your neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698c31bc",
   "metadata": {},
   "source": [
    "### backward(): \n",
    "- This is the most famous method in PyTorch. When you call loss.backward(), PyTorch travels backward through the Computational Graph, calculating the gradient of the loss with respect to every tensor that has requires_grad=True."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8600d768",
   "metadata": {},
   "source": [
    "### grad: \n",
    "- After calling .backward(), the calculated gradients are stored in this attribute of the tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a9f1539d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If x is a weight, x.grad tells us: \n",
    "# \"How much will the loss change if I move x slightly?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e414eadd",
   "metadata": {},
   "source": [
    "### grad_fn: \n",
    "- Every tensor created by an operation (like y = x + 2) has a grad_fn. This is a reference to the function that created it, allowing PyTorch to trace the path back to the inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2ef93e",
   "metadata": {},
   "source": [
    "### zero_grad(): \n",
    "- Gradients in PyTorch accumulate (add up) by default. Before you start a new calculation, you must call this to wipe the old gradients clean, otherwise your model will get \"confused\" by previous training steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26de8605",
   "metadata": {},
   "source": [
    "### Efficiency & Inference \n",
    "- When you are just using a model to make predictions (Inference), you don't need gradients. Disabling them saves massive amounts of memory and speed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e649db6e",
   "metadata": {},
   "source": [
    "#### torch.no_grad(): \n",
    "- A context manager used during validation or testing. It tells PyTorch: \"Don't track anything here; I'm not training.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "15a5d395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction from model, use for inference\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    # prediction = model(input_data)\n",
    "    print(\"Prediction from model, use for inference\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffff69d7",
   "metadata": {},
   "source": [
    "#### torch.enable_grad(): \n",
    "- The opposite of no_grad, used if you need to force-enable tracking within a block that was otherwise disabled."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be8e20e",
   "metadata": {},
   "source": [
    "#### is_grad_enabled(): \n",
    "- A simple check to see if PyTorch is currently recording history for gradients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a8e204",
   "metadata": {},
   "source": [
    "### Graph Surgery\n",
    "- Sometimes you need to \"break\" the graph or save specific parts of it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4606c1c0",
   "metadata": {},
   "source": [
    "#### detach(): \n",
    "- Returns a new tensor that is \"cut off\" from the computational graph. It shares the same data but will never track gradients. This is common when you want to use a value for a side-calculation without affecting the model's training.\n",
    "\n",
    "#### clone(): \n",
    "- Creates a copy of the tensor that stays in the graph. If you modify the clone, the gradients will still flow back to the original source.\n",
    "\n",
    "#### retain_grad(): \n",
    "- By default, PyTorch only saves gradients for \"leaf\" tensors (your weights). If you want to see the gradient for an intermediate activation (like the output of a hidden layer), you must call this on that tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
