{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fc53a90",
   "metadata": {},
   "source": [
    "# torch.nn.parameter.Buffer\n",
    "\n",
    "- **Buffer** нь PyTorch-ийн параметр биш ч гэсэн сүлжээний хэсэг болох тогтмол өгөгдлийг хадгалахад зориулагдсан. Энэ нь суралцагдах параметрүүдээс (nn.Parameter) ялгаатай нь градиент тооцоонд ордоггүй, буцаан суралцагдахгүй утгууд юм."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59fb041",
   "metadata": {},
   "source": [
    "## Суурь хэрэглээ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e6762b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Суралцагдах параметр\n",
    "        self.weight = nn.Parameter(torch.randn(hidden_size, input_size))\n",
    "        \n",
    "        # Buffer (суралцагдахгүй тогтмол утга)\n",
    "        self.register_buffer('running_mean', torch.zeros(hidden_size))\n",
    "        self.register_buffer('running_var', torch.ones(hidden_size))\n",
    "        \n",
    "        # persistent=False үед state_dict-д хадгалагдахгүй\n",
    "        self.register_buffer('temp_buffer', torch.tensor([1.0, 2.0, 3.0]), persistent=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Buffer ашиглах\n",
    "        normalized = (x - self.running_mean) / torch.sqrt(self.running_var + 1e-5)\n",
    "        return torch.matmul(normalized, self.weight.t())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ff81159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter - Name: weight, Shape: torch.Size([5, 10])\n",
      "tensor([0., 0., 0., 0., 0.])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "OrderedDict([('weight', tensor([[-0.3374,  0.4554,  0.4736, -0.6821,  0.8839,  2.9157, -0.7849,  0.2084,\n",
      "          1.1419,  2.0074],\n",
      "        [-2.2716, -2.0676,  1.7437,  1.8423,  1.0641, -1.8200, -2.3000,  0.1482,\n",
      "          0.5342, -0.4623],\n",
      "        [-0.1153,  0.6981,  1.2750,  0.6758, -0.6575, -0.4092,  0.0484,  0.9167,\n",
      "          0.1040,  0.8143],\n",
      "        [ 0.0188,  0.8150,  1.5313, -0.4581,  1.3372,  0.8090, -0.7218,  0.2599,\n",
      "         -0.5052,  1.2041],\n",
      "        [ 1.3950,  0.4390, -1.4032,  1.4993,  1.4297, -0.4141,  0.1363,  0.1492,\n",
      "          0.7302, -0.1614]])), ('running_mean', tensor([0., 0., 0., 0., 0.])), ('running_var', tensor([1., 1., 1., 1., 1.]))])\n"
     ]
    }
   ],
   "source": [
    "model = MyModel(input_size=10, hidden_size=5)\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Parameter - Name: {name}, Shape: {param.shape}\")\n",
    "print(model.running_mean)    \n",
    "print(model.running_var)\n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4777c3b0",
   "metadata": {},
   "source": [
    "## Тодорхойлолт:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "666647bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.parameter.Buffer(data=None, persistent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9bdede",
   "metadata": {},
   "source": [
    "- **data** (Tensor): Buffer-т хадгалагдах тензор\n",
    "\n",
    "- **persistent** (bool): True үед state_dict-д хадгалагдана. False үед хадгалагдахгүй"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4834265b",
   "metadata": {},
   "source": [
    "## Жишээнүүд:\n",
    "\n",
    "### 1. Үндсэн Buffer бүртгэх"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5200f2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Buffer бүртгэх арга 1: register_buffer ашиглах\n",
    "        self.register_buffer('mean', torch.tensor([0.0]))\n",
    "        self.register_buffer('std', torch.tensor([1.0]))\n",
    "        \n",
    "        # Buffer бүртгэх арга 2: Шууд үүсгэх\n",
    "        self.count = torch.tensor(0)  # Энэ нь buffer болохгүй!\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Зөвхөн бүртгэгдсэн buffer-ууд л зөв ажиллана\n",
    "        return (x - self.mean) / self.std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1fd902",
   "metadata": {},
   "source": [
    "### 2. BatchNorm дэх buffer-ын жишээ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38f5a270",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomBatchNorm(nn.Module):\n",
    "    def __init__(self, num_features, momentum=0.1):\n",
    "        super().__init__()\n",
    "        self.num_features = num_features\n",
    "        self.momentum = momentum\n",
    "        \n",
    "        # Суралцагдах параметрүүд\n",
    "        self.weight = nn.Parameter(torch.ones(num_features))\n",
    "        self.bias = nn.Parameter(torch.zeros(num_features))\n",
    "        \n",
    "        # Суралцагдахгүй buffer-ууд\n",
    "        self.register_buffer('running_mean', torch.zeros(num_features))\n",
    "        self.register_buffer('running_var', torch.ones(num_features))\n",
    "        self.register_buffer('num_batches_tracked', torch.tensor(0, dtype=torch.long))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            # Сургалтын горимд статистик шинэчлэх\n",
    "            mean = x.mean(dim=0)\n",
    "            var = x.var(dim=0, unbiased=False)\n",
    "            \n",
    "            # Exponential moving average\n",
    "            self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * mean\n",
    "            self.running_var = (1 - self.momentum) * self.running_var + self.momentum * var\n",
    "            self.num_batches_tracked += 1\n",
    "            \n",
    "            # Normalize\n",
    "            x_normalized = (x - mean) / torch.sqrt(var + 1e-5)\n",
    "        else:\n",
    "            # Шалгалтын горимд хадгалсан статистик ашиглах\n",
    "            x_normalized = (x - self.running_mean) / torch.sqrt(self.running_var + 1e-5)\n",
    "        \n",
    "        return self.weight * x_normalized + self.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73805695",
   "metadata": {},
   "source": [
    "### 3. Positional Encoding buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "096dbe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # Positional encoding-ийг buffer хэлбэрээр хадгалах\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * \n",
    "                           (-torch.log(torch.tensor(10000.0)) / d_model))\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        \n",
    "        self.register_buffer('pe', pe)  # Нэг удаа тооцоолж хадгалах\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Positional encoding нэмэх\n",
    "        seq_len = x.size(1)\n",
    "        return x + self.pe[:, :seq_len]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98ca4ea",
   "metadata": {},
   "source": [
    "### 4. Persistent vs Non-persistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bba76ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BufferExample(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Persistent buffer (state_dict-д хадгалагдана)\n",
    "        self.register_buffer('important_stats', \n",
    "                           torch.tensor([1.0, 2.0, 3.0]), \n",
    "                           persistent=True)\n",
    "        \n",
    "        # Non-persistent buffer (state_dict-д хадгалагдахгүй)\n",
    "        self.register_buffer('temp_cache', \n",
    "                           torch.zeros(10, 10), \n",
    "                           persistent=False)\n",
    "        \n",
    "        # persistent параметрийн анхны утга: True\n",
    "        self.register_buffer('default_buffer', torch.ones(5))\n",
    "    \n",
    "    def state_dict_example(self):\n",
    "        # state_dict-ыг харах\n",
    "        state = self.state_dict()\n",
    "        print(\"State dict keys:\", list(state.keys()))\n",
    "        # Гаралт: ['important_stats', 'default_buffer']\n",
    "        # 'temp_cache' хамаарахгүй!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5069749",
   "metadata": {},
   "source": [
    "## Бусад хэрэглээ:\n",
    "### 1. Маск хадгалах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03b7f558",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedLayer(nn.Module):\n",
    "    def __init__(self, size):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Маскийг buffer хэлбэрээр хадгалах\n",
    "        mask = torch.tril(torch.ones(size, size))\n",
    "        self.register_buffer('mask', mask)\n",
    "        \n",
    "        self.weight = nn.Parameter(torch.randn(size, size))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Маск ашиглан жинг хязгаарлах\n",
    "        masked_weight = self.weight * self.mask\n",
    "        return torch.matmul(x, masked_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c8ea89",
   "metadata": {},
   "source": [
    "### 2. Look-up хүснэгт"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b0098a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LookupTable(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Embedding параметр\n",
    "        self.embedding = nn.Parameter(torch.randn(vocab_size, embedding_dim))\n",
    "        \n",
    "        # Precomputed frequency table (buffer)\n",
    "        freq = torch.ones(vocab_size) / vocab_size\n",
    "        self.register_buffer('frequency', freq)\n",
    "        \n",
    "        # Positional index (buffer)\n",
    "        positions = torch.arange(vocab_size)\n",
    "        self.register_buffer('pos_indices', positions)\n",
    "    \n",
    "    def forward(self, token_ids):\n",
    "        embeddings = self.embedding[token_ids]\n",
    "        weighted = embeddings * self.frequency[token_ids].unsqueeze(-1)\n",
    "        return weighted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86df7094",
   "metadata": {},
   "source": [
    "## Чухал шинж чанарууд:\n",
    "### Buffer-ын онцлог:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b82a7574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requires grad: False\n",
      "Is parameter: False\n",
      "In parameters(): False\n",
      "In buffers(): True\n"
     ]
    }
   ],
   "source": [
    "model = nn.Module()\n",
    "\n",
    "# Buffer үүсгэх\n",
    "model.register_buffer('my_buffer', torch.tensor([1.0, 2.0, 3.0]))\n",
    "\n",
    "# Шинж чанарууд:\n",
    "print(\"Requires grad:\", model.my_buffer.requires_grad)  # False\n",
    "print(\"Is parameter:\", isinstance(model.my_buffer, nn.Parameter))  # False\n",
    "print(\"In parameters():\", 'my_buffer' in dict(model.named_parameters()))  # False\n",
    "print(\"In buffers():\", 'my_buffer' in dict(model.named_buffers()))  # True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe9ee11",
   "metadata": {},
   "source": [
    "### Buffer-тай ажиллах:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c07b7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BufferOperations(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.register_buffer('stats', torch.zeros(3))\n",
    "    \n",
    "    def update_buffer(self, new_data):\n",
    "        # Buffer шинэчлэх (градиент шаардлагагүй)\n",
    "        with torch.no_grad():\n",
    "            self.stats += new_data\n",
    "    \n",
    "    def reset_buffer(self):\n",
    "        # Buffer дахин эхлүүлэх\n",
    "        self.stats.zero_()\n",
    "    \n",
    "    def use_buffer_in_computation(self, x):\n",
    "        # Buffer тооцоололд ашиглах\n",
    "        # Градиент buffer-аас үүсэхгүй\n",
    "        return x * self.stats.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db30fa7",
   "metadata": {},
   "source": [
    "## Анхаарах зүйлс:\n",
    "\n",
    "- Градиент: Buffer-ууд requires_grad=False байна\n",
    "\n",
    "- Хөдөлгөөн: to(device), cpu(), cuda() зэрэг үйлдлүүд buffer-уудад нөлөөлнө\n",
    "\n",
    "- Хадгалалт: torch.save()/torch.load() үйлдлүүд persistent buffer-уудыг хадгална\n",
    "\n",
    "- Клончлох: copy.deepcopy() нь buffer-уудыг зөв хуулах болно\n",
    "\n",
    "- Төрөл: Buffer нь тензорын төрөл, device-тэй нийцэх ёстой\n",
    "\n",
    "## Практик зөвлөмж:\n",
    "\n",
    "1. Батч нормалчлал: Статистик мэдээллийг buffer-д хадгал\n",
    "\n",
    "2. Кэш: Давтан тооцоолол хийхгүйгээр үр дүнг хадгал\n",
    "\n",
    "3. Маск: Градиент шаардлагагүй тогтмол матрицууд\n",
    "\n",
    "4. Тохиргоо: Моделийн тохиргоог хадгалах\n",
    "\n",
    "5. Тоолуур: Давталт, алхамыг тоолох\n",
    "\n",
    "Buffer нь PyTorch моделд тогтмол, суралцагдахгүй өгөгдлийг үр дүнтэй хадгалахад чухал үүрэгтэй."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b8c880",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
